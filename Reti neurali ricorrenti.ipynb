{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di esempi del dataset: 25000\n",
      "Numero di esempi del test: 25000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import imdb\n",
    "\n",
    "num_words=10000\n",
    "\n",
    "(X_train, y_train) , (X_test, y_test) = imdb.load_data(num_words=num_words)\n",
    "print('Numero di esempi del dataset: %d' % X_train.shape[0])\n",
    "print('Numero di esempi del test: %d' % X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nel caso di reti neurali ricorrenti non conviene utilizzare il one hot encoding, ma il word embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1014,\n",
       " 300,\n",
       " 4349,\n",
       " 768,\n",
       " 2702,\n",
       " 1014,\n",
       " 2,\n",
       " 1538,\n",
       " 5,\n",
       " 3483,\n",
       " 5934,\n",
       " 1918,\n",
       " 1812,\n",
       " 2,\n",
       " 5,\n",
       " 1378,\n",
       " 9125,\n",
       " 2,\n",
       " 1538,\n",
       " 5,\n",
       " 3483,\n",
       " 5934,\n",
       " 645,\n",
       " 183,\n",
       " 125,\n",
       " 19,\n",
       " 6,\n",
       " 4349,\n",
       " 768,\n",
       " 2702,\n",
       " 1014,\n",
       " 429,\n",
       " 1812,\n",
       " 2,\n",
       " 5,\n",
       " 1378,\n",
       " 9125,\n",
       " 1793,\n",
       " 8,\n",
       " 4,\n",
       " 2269,\n",
       " 7,\n",
       " 4,\n",
       " 1014,\n",
       " 199,\n",
       " 9149,\n",
       " 28,\n",
       " 8,\n",
       " 140,\n",
       " 143,\n",
       " 8915,\n",
       " 11,\n",
       " 661,\n",
       " 8,\n",
       " 79,\n",
       " 4,\n",
       " 1176,\n",
       " 9125,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 56,\n",
       " 402,\n",
       " 23,\n",
       " 34,\n",
       " 656,\n",
       " 505,\n",
       " 2,\n",
       " 86,\n",
       " 3483,\n",
       " 5,\n",
       " 95,\n",
       " 2,\n",
       " 1538,\n",
       " 6,\n",
       " 1124,\n",
       " 2,\n",
       " 34,\n",
       " 9125,\n",
       " 8,\n",
       " 2,\n",
       " 562,\n",
       " 4,\n",
       " 1933,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 5934,\n",
       " 597,\n",
       " 3483,\n",
       " 805,\n",
       " 8,\n",
       " 339,\n",
       " 27,\n",
       " 597,\n",
       " 21,\n",
       " 4,\n",
       " 2,\n",
       " 6075,\n",
       " 90,\n",
       " 137,\n",
       " 9125,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 56,\n",
       " 23,\n",
       " 90,\n",
       " 11,\n",
       " 4,\n",
       " 3130,\n",
       " 19,\n",
       " 9125,\n",
       " 2,\n",
       " 245,\n",
       " 23,\n",
       " 2,\n",
       " 2,\n",
       " 270,\n",
       " 56,\n",
       " 6,\n",
       " 2702,\n",
       " 1005,\n",
       " 3483,\n",
       " 2,\n",
       " 83,\n",
       " 4,\n",
       " 1746,\n",
       " 5,\n",
       " 2,\n",
       " 120,\n",
       " 4,\n",
       " 350,\n",
       " 5836,\n",
       " 1646,\n",
       " 2,\n",
       " 23,\n",
       " 4,\n",
       " 1005,\n",
       " 103,\n",
       " 9026,\n",
       " 5,\n",
       " 656,\n",
       " 459,\n",
       " 7,\n",
       " 3483,\n",
       " 2,\n",
       " 9491,\n",
       " 6,\n",
       " 2702,\n",
       " 83,\n",
       " 4,\n",
       " 1746,\n",
       " 5,\n",
       " 1678,\n",
       " 4,\n",
       " 2,\n",
       " 270,\n",
       " 12,\n",
       " 56,\n",
       " 4,\n",
       " 2,\n",
       " 95,\n",
       " 270,\n",
       " 56,\n",
       " 18,\n",
       " 6,\n",
       " 1405,\n",
       " 2,\n",
       " 39,\n",
       " 4,\n",
       " 655,\n",
       " 5836,\n",
       " 63,\n",
       " 62,\n",
       " 28,\n",
       " 276,\n",
       " 2,\n",
       " 143,\n",
       " 4,\n",
       " 2702,\n",
       " 21,\n",
       " 3483,\n",
       " 5290,\n",
       " 4,\n",
       " 2702,\n",
       " 120,\n",
       " 208,\n",
       " 159,\n",
       " 27,\n",
       " 597,\n",
       " 385,\n",
       " 6668,\n",
       " 180,\n",
       " 2,\n",
       " 5,\n",
       " 9125,\n",
       " 2,\n",
       " 160,\n",
       " 2702,\n",
       " 11,\n",
       " 4,\n",
       " 3130,\n",
       " 5,\n",
       " 805,\n",
       " 8,\n",
       " 2531,\n",
       " 8105,\n",
       " 3483,\n",
       " 143,\n",
       " 12,\n",
       " 21,\n",
       " 2,\n",
       " 2,\n",
       " 11,\n",
       " 5,\n",
       " 2,\n",
       " 27,\n",
       " 597,\n",
       " 2,\n",
       " 1059,\n",
       " 968,\n",
       " 5,\n",
       " 5671,\n",
       " 199,\n",
       " 9149,\n",
       " 83,\n",
       " 145,\n",
       " 648,\n",
       " 4214,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 3483,\n",
       " 2,\n",
       " 23,\n",
       " 4,\n",
       " 2,\n",
       " 39,\n",
       " 125,\n",
       " 4,\n",
       " 350,\n",
       " 5836,\n",
       " 2,\n",
       " 1428,\n",
       " 9125,\n",
       " 33,\n",
       " 4778,\n",
       " 18,\n",
       " 3483,\n",
       " 8,\n",
       " 2,\n",
       " 83,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3633,\n",
       " 103,\n",
       " 9125,\n",
       " 2,\n",
       " 3483,\n",
       " 11,\n",
       " 4,\n",
       " 2,\n",
       " 21,\n",
       " 4,\n",
       " 1014,\n",
       " 3501,\n",
       " 60,\n",
       " 103,\n",
       " 3483,\n",
       " 2,\n",
       " 46,\n",
       " 2,\n",
       " 385,\n",
       " 8,\n",
       " 27,\n",
       " 5842,\n",
       " 2232,\n",
       " 5,\n",
       " 1319,\n",
       " 8,\n",
       " 2,\n",
       " 9125,\n",
       " 23,\n",
       " 6,\n",
       " 2702,\n",
       " 2,\n",
       " 2,\n",
       " 39,\n",
       " 4,\n",
       " 655,\n",
       " 5836,\n",
       " 21,\n",
       " 9125,\n",
       " 1681,\n",
       " 5,\n",
       " 1412,\n",
       " 2,\n",
       " 6668,\n",
       " 143,\n",
       " 4,\n",
       " 2137,\n",
       " 21,\n",
       " 88,\n",
       " 27,\n",
       " 9149,\n",
       " 161,\n",
       " 1147,\n",
       " 90,\n",
       " 143,\n",
       " 4,\n",
       " 2702,\n",
       " 2,\n",
       " 16,\n",
       " 1668,\n",
       " 8,\n",
       " 789,\n",
       " 11,\n",
       " 4,\n",
       " 1014,\n",
       " 4,\n",
       " 86,\n",
       " 132,\n",
       " 16,\n",
       " 9751,\n",
       " 3633,\n",
       " 103,\n",
       " 151,\n",
       " 17,\n",
       " 3483,\n",
       " 276,\n",
       " 1812,\n",
       " 143,\n",
       " 6,\n",
       " 2702,\n",
       " 19,\n",
       " 6,\n",
       " 5934,\n",
       " 2,\n",
       " 39,\n",
       " 4,\n",
       " 1746,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 1005,\n",
       " 9125,\n",
       " 276,\n",
       " 3483,\n",
       " 143,\n",
       " 6,\n",
       " 2702,\n",
       " 388,\n",
       " 303,\n",
       " 8,\n",
       " 60,\n",
       " 4,\n",
       " 603,\n",
       " 746,\n",
       " 1574,\n",
       " 2,\n",
       " 9309,\n",
       " 6,\n",
       " 2,\n",
       " 2165,\n",
       " 15,\n",
       " 276,\n",
       " 9125,\n",
       " 143,\n",
       " 6,\n",
       " 2702,\n",
       " 5,\n",
       " 520,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1176,\n",
       " 2286,\n",
       " 2,\n",
       " 1538,\n",
       " 5,\n",
       " 3483,\n",
       " 5934,\n",
       " 10,\n",
       " 10,\n",
       " 1014,\n",
       " 241,\n",
       " 2,\n",
       " 4990,\n",
       " 3546,\n",
       " 3143,\n",
       " 1918,\n",
       " 1514,\n",
       " 6011,\n",
       " 1514,\n",
       " 6011,\n",
       " 5235,\n",
       " 3546,\n",
       " 3143,\n",
       " 37,\n",
       " 839,\n",
       " 2,\n",
       " 19,\n",
       " 90,\n",
       " 8,\n",
       " 4,\n",
       " 1746,\n",
       " 18,\n",
       " 4,\n",
       " 2,\n",
       " 4990,\n",
       " 3143,\n",
       " 5,\n",
       " 6011,\n",
       " 2897,\n",
       " 56,\n",
       " 5,\n",
       " 2,\n",
       " 120,\n",
       " 4,\n",
       " 1746,\n",
       " 21,\n",
       " 2,\n",
       " 145,\n",
       " 1004,\n",
       " 5,\n",
       " 2,\n",
       " 49,\n",
       " 53,\n",
       " 54,\n",
       " 6011,\n",
       " 2,\n",
       " 32,\n",
       " 2,\n",
       " 1102,\n",
       " 3143,\n",
       " 2,\n",
       " 1005,\n",
       " 4,\n",
       " 1746,\n",
       " 121,\n",
       " 2,\n",
       " 520,\n",
       " 90,\n",
       " 49,\n",
       " 2,\n",
       " 4,\n",
       " 548,\n",
       " 4600,\n",
       " 1005,\n",
       " 4,\n",
       " 1746,\n",
       " 5,\n",
       " 3143,\n",
       " 3913,\n",
       " 27,\n",
       " 980,\n",
       " 83,\n",
       " 4,\n",
       " 2,\n",
       " 6011,\n",
       " 6265,\n",
       " 2,\n",
       " 1212,\n",
       " 21,\n",
       " 16,\n",
       " 623,\n",
       " 180,\n",
       " 19,\n",
       " 6,\n",
       " 2,\n",
       " 3131,\n",
       " 1449,\n",
       " 3143,\n",
       " 3501,\n",
       " 8,\n",
       " 1274,\n",
       " 2,\n",
       " 6180,\n",
       " 3131,\n",
       " 145,\n",
       " 11,\n",
       " 4,\n",
       " 1746,\n",
       " 2,\n",
       " 6180,\n",
       " 5395,\n",
       " 2,\n",
       " 27,\n",
       " 8158,\n",
       " 21,\n",
       " 29,\n",
       " 3501,\n",
       " 8,\n",
       " 985,\n",
       " 254,\n",
       " 3143,\n",
       " 805,\n",
       " 8,\n",
       " 276,\n",
       " 6011,\n",
       " 245,\n",
       " 19,\n",
       " 6,\n",
       " 2,\n",
       " 21,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 83,\n",
       " 6,\n",
       " 2,\n",
       " 6011,\n",
       " 435,\n",
       " 8,\n",
       " 1363,\n",
       " 183,\n",
       " 19,\n",
       " 6,\n",
       " 1205,\n",
       " 323,\n",
       " 3534,\n",
       " 21,\n",
       " 3143,\n",
       " 3095,\n",
       " 56,\n",
       " 4,\n",
       " 589,\n",
       " 6011,\n",
       " 435,\n",
       " 18,\n",
       " 4,\n",
       " 1205,\n",
       " 323,\n",
       " 3534,\n",
       " 174,\n",
       " 21,\n",
       " 14,\n",
       " 58,\n",
       " 3143,\n",
       " 43,\n",
       " 4985,\n",
       " 46,\n",
       " 7,\n",
       " 2,\n",
       " 96,\n",
       " 3143,\n",
       " 2,\n",
       " 6011,\n",
       " 83,\n",
       " 6,\n",
       " 671,\n",
       " 2165,\n",
       " 515,\n",
       " 103,\n",
       " 5,\n",
       " 188,\n",
       " 4,\n",
       " 5012,\n",
       " 8,\n",
       " 9716,\n",
       " 27,\n",
       " 5524,\n",
       " 2,\n",
       " 4990,\n",
       " 2286,\n",
       " 3546,\n",
       " 3143,\n",
       " 10,\n",
       " 10,\n",
       " 1014,\n",
       " 342,\n",
       " 1874,\n",
       " 4990,\n",
       " 1024,\n",
       " 9617,\n",
       " 1918,\n",
       " 1808,\n",
       " 2966,\n",
       " 1024,\n",
       " 9617,\n",
       " 562,\n",
       " 23,\n",
       " 1808,\n",
       " 2966,\n",
       " 375,\n",
       " 11,\n",
       " 35,\n",
       " 589,\n",
       " 8,\n",
       " 1176,\n",
       " 145,\n",
       " 4,\n",
       " 1874,\n",
       " 4990,\n",
       " 1808,\n",
       " 2,\n",
       " 9617,\n",
       " 120,\n",
       " 4,\n",
       " 350,\n",
       " 5836,\n",
       " 95,\n",
       " 562,\n",
       " 90,\n",
       " 180,\n",
       " 19,\n",
       " 6,\n",
       " 2,\n",
       " 125,\n",
       " 4,\n",
       " 1746,\n",
       " 2,\n",
       " 145,\n",
       " 11,\n",
       " 4,\n",
       " 1746,\n",
       " 1808,\n",
       " 569,\n",
       " 4,\n",
       " 2,\n",
       " 11,\n",
       " 4,\n",
       " 1933,\n",
       " 8,\n",
       " 3296,\n",
       " 9617,\n",
       " 18,\n",
       " 6,\n",
       " 9522,\n",
       " 1808,\n",
       " 435,\n",
       " 18,\n",
       " 4,\n",
       " 2,\n",
       " 2165,\n",
       " 21,\n",
       " 9617,\n",
       " 188,\n",
       " 27,\n",
       " 8135,\n",
       " 56,\n",
       " 8,\n",
       " 569,\n",
       " 1808,\n",
       " 19,\n",
       " 6,\n",
       " 6425,\n",
       " 324,\n",
       " 1808,\n",
       " 1319,\n",
       " 8,\n",
       " 866,\n",
       " 9617,\n",
       " 19,\n",
       " 6,\n",
       " 1605,\n",
       " 2,\n",
       " 151,\n",
       " 5,\n",
       " 188,\n",
       " 4,\n",
       " 5012,\n",
       " 8,\n",
       " 401,\n",
       " 4,\n",
       " 1874,\n",
       " 4990,\n",
       " 9617,\n",
       " 645,\n",
       " 2,\n",
       " 33,\n",
       " 319,\n",
       " 2966,\n",
       " 8265,\n",
       " 23,\n",
       " 27,\n",
       " 96,\n",
       " 145,\n",
       " 56,\n",
       " 4,\n",
       " 2,\n",
       " 2286,\n",
       " 1808,\n",
       " 2966,\n",
       " 10,\n",
       " 10,\n",
       " 1014,\n",
       " 470,\n",
       " 1378,\n",
       " 2,\n",
       " 1918,\n",
       " 308,\n",
       " 7702,\n",
       " 1378,\n",
       " 2,\n",
       " 69,\n",
       " 4407,\n",
       " 8,\n",
       " 130,\n",
       " 308,\n",
       " 2,\n",
       " 611,\n",
       " 11,\n",
       " 68,\n",
       " 1014,\n",
       " 33,\n",
       " 4546,\n",
       " 63,\n",
       " 385,\n",
       " 56,\n",
       " 375,\n",
       " 2,\n",
       " 805,\n",
       " 8,\n",
       " 3336,\n",
       " 7702,\n",
       " 6,\n",
       " 2037,\n",
       " 17,\n",
       " 68,\n",
       " 1014,\n",
       " 1695,\n",
       " 34,\n",
       " 2,\n",
       " 90,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3501,\n",
       " 8,\n",
       " 3296,\n",
       " 7702,\n",
       " 187,\n",
       " 4,\n",
       " 1746,\n",
       " 366,\n",
       " 27,\n",
       " 2,\n",
       " 188,\n",
       " 4,\n",
       " 128,\n",
       " 7,\n",
       " 90,\n",
       " 137,\n",
       " 23,\n",
       " 4,\n",
       " 350,\n",
       " 5836,\n",
       " 2,\n",
       " 1695,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 1668,\n",
       " 7702,\n",
       " 8,\n",
       " 4003,\n",
       " 90,\n",
       " 18,\n",
       " 6,\n",
       " 2,\n",
       " 7702,\n",
       " 1477,\n",
       " 19,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 8264,\n",
       " 21,\n",
       " 16,\n",
       " 623,\n",
       " 180,\n",
       " 19,\n",
       " 6,\n",
       " 1606,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 5565,\n",
       " 4,\n",
       " 6655,\n",
       " 2,\n",
       " 5,\n",
       " 569,\n",
       " 6,\n",
       " 6380,\n",
       " 8,\n",
       " 6380,\n",
       " 2,\n",
       " 21,\n",
       " 426,\n",
       " 276,\n",
       " 2,\n",
       " 245,\n",
       " 2,\n",
       " 8732,\n",
       " 83,\n",
       " 4,\n",
       " 2,\n",
       " 21,\n",
       " 7702,\n",
       " 2,\n",
       " 4,\n",
       " 847,\n",
       " 2,\n",
       " 9309,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 95,\n",
       " 3168,\n",
       " 23,\n",
       " 4,\n",
       " 2,\n",
       " 21,\n",
       " 122,\n",
       " 24,\n",
       " 140,\n",
       " 18,\n",
       " 4,\n",
       " 1108,\n",
       " 29,\n",
       " 2,\n",
       " 7702,\n",
       " 8,\n",
       " 27,\n",
       " 2194,\n",
       " 38,\n",
       " 29,\n",
       " 100,\n",
       " 276,\n",
       " 23,\n",
       " 4,\n",
       " 3404,\n",
       " 7,\n",
       " 2,\n",
       " 7702,\n",
       " 69,\n",
       " 85,\n",
       " 1008,\n",
       " 2,\n",
       " 4,\n",
       " 847,\n",
       " 83,\n",
       " 6,\n",
       " 5012,\n",
       " 589,\n",
       " 5,\n",
       " 397,\n",
       " 4,\n",
       " 300,\n",
       " 241,\n",
       " 342,\n",
       " 2,\n",
       " 435,\n",
       " 2,\n",
       " 103,\n",
       " 4,\n",
       " 1014,\n",
       " 2286,\n",
       " 308,\n",
       " 7702,\n",
       " 10,\n",
       " 10,\n",
       " 1014,\n",
       " 457,\n",
       " 2,\n",
       " 4990,\n",
       " 2,\n",
       " 1918,\n",
       " 2,\n",
       " 2,\n",
       " 2864,\n",
       " 2,\n",
       " 4,\n",
       " 375,\n",
       " 194,\n",
       " 155,\n",
       " 5,\n",
       " 443,\n",
       " 990,\n",
       " 3113,\n",
       " 650,\n",
       " 2,\n",
       " 19,\n",
       " 4,\n",
       " 2,\n",
       " 4990,\n",
       " 23,\n",
       " 4,\n",
       " 347,\n",
       " 2,\n",
       " 7258,\n",
       " 4,\n",
       " 425,\n",
       " 39,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 12,\n",
       " 120,\n",
       " 27,\n",
       " 5447,\n",
       " 2,\n",
       " 137,\n",
       " 6533,\n",
       " 33,\n",
       " 2,\n",
       " 1171,\n",
       " 2,\n",
       " 3579,\n",
       " 2,\n",
       " 520,\n",
       " 2,\n",
       " 2352,\n",
       " 402,\n",
       " 23,\n",
       " 4,\n",
       " 194,\n",
       " 132,\n",
       " 4985,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 1746,\n",
       " 5,\n",
       " 4365,\n",
       " 4,\n",
       " 4587,\n",
       " 3183,\n",
       " 46,\n",
       " 7,\n",
       " 4185,\n",
       " 2,\n",
       " 1906,\n",
       " 309,\n",
       " 295,\n",
       " 5,\n",
       " 1695,\n",
       " 8,\n",
       " 193,\n",
       " 2909,\n",
       " 19,\n",
       " 723,\n",
       " 2,\n",
       " 2,\n",
       " 33,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 254,\n",
       " 1873,\n",
       " 1005,\n",
       " 4,\n",
       " 1746,\n",
       " 39,\n",
       " 50,\n",
       " 2,\n",
       " 1695,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 2825,\n",
       " 90,\n",
       " 19,\n",
       " 3964,\n",
       " 120,\n",
       " 4,\n",
       " 350,\n",
       " 5836,\n",
       " 2,\n",
       " 5955,\n",
       " 2149,\n",
       " 23,\n",
       " 27,\n",
       " 145,\n",
       " 95,\n",
       " 69,\n",
       " 8,\n",
       " 2712,\n",
       " 39,\n",
       " 260,\n",
       " 27,\n",
       " 6235,\n",
       " 2,\n",
       " 429,\n",
       " 4,\n",
       " 4587,\n",
       " 1746,\n",
       " 3183,\n",
       " ...]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vediamo quanto è lunga la più lunga recensione all'interno del corpus di testo\n",
    "longest_review = max(X_train, key=len)  #viene effettuata la ricerca per lunghezza massima\n",
    "len(longest_review)                     #2494 parole\n",
    "longest_review                          #contiene gli indici delle parole nel dizionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? match 1 tag team table match ? ray and spike dudley vs eddie ? and chris benoit ? ray and spike dudley started things off with a tag team table match against eddie ? and chris benoit according to the rules of the match both opponents have to go through tables in order to get the win benoit and ? ? up early on by taking turns ? first spike and then ? ray a german ? by benoit to ? took the wind out of the dudley brother spike tried to help his brother but the ? restrained him while benoit and ? ? up on him in the corner with benoit ? away on ? ? set up a table outside spike ? into the ring and ? over the top rope onto ? on the outside after recovering and taking care of spike ? slipped a table into the ring and helped the ? set it up the ? then set up for a double ? from the middle rope which would have put ? through the table but spike knocked the table over right before his brother came crashing down ? and benoit ? another table in the corner and tried to irish whip spike through it but ? ? in and ? his brother ? caught fire and lifted both opponents into back body drops ? ? ? and spike ? on the ? from off the top rope ? held benoit at bay for spike to ? into the ? ? shortly after benoit ? spike in the ? but the match continued even after spike ? out ? came to his brother's rescue and managed to ? benoit on a table ? ? from the middle rope but benoit moved and sent ? crashing through the wood but because his opponents didn't force him through the table ? was allowed to stay in the match the first man was eliminated shortly after though as spike put eddie through a table with a dudley ? from the ring ? to the outside benoit put spike through a table moments later to even the score within seconds ? nailed a ? bomb that put benoit through a table and gave the ? the win winner ? ray and spike dudley br br match 2 ? championship jamie noble vs billy kidman billy kidman challenged jamie noble who brought ? with him to the ring for the ? championship noble and kidman locked up and ? over the ring but ? back inside and ? some more when kidman ? all ? moves noble ? outside the ring where ? gave him some ? the fight spread outside the ring and noble threw his girlfriend into the ? kidman tossed ? aside but was taken down with a ? arm bar noble continued to attack ? injured arm back in the ring ? injured harm ? his offense but he continued to battle hard noble tried to put kidman away with a ? but the ? ? into a ? kidman went to finish things with a shooting star press but noble broke up the attempt kidman went for the shooting star press again but this time noble just rolled out of ? way noble ? kidman into a power bomb soon after and got the pin to retain his wwe ? championship winner jamie noble br br match 3 european championship william regal vs jeff hardy william regal took on jeff hardy next in an attempt to win back the european championship jeff ? regal over the top rope then took him down with a ? off the ring ? back in the ring jeff hit the ? in the wind to knock regal for a loop jeff went for the ? bomb but regal got his knees up to hit jeff with a devastating shot jeff managed to surprise regal with a quick ? though and got the pin to keep the european championship regal started ? at seeing hardy celebrate on his way back up the ? winner jeff hardy br br match 4 chris ? vs john cena chris ? had promised to end john ? career in their match at vengeance which came up next ? tried to teach cena a lesson as their match began by ? him to the ? ? continued to knock cena around the ring until his ? got the better of him while on the top rope ? began to ? and allowed cena to grab him for a ? cena followed with a ? a ? slam but was taken down with a nasty ? to the gut the rookie ? and hit a belly to belly ? but couldn't put ? away ? launched into the ? but cena ? the move ? nailed a ? and then connected on the ? but did not go for the cover he ? cena to his feet so he could put on the walls of ? cena had other ideas ? the move into a pin attempt and getting the 1 2 3 ? went ? after the match winner john cena br br match 5 ? championship ? vs ? ? via ? the next big thing and mr pay per view ? with the ? championship on the line ? grabbed the title from the ? and ? it over his shoulder ? while glaring at ? van ? 's ? gave ? fits early on the big man rolled out of the ring and kicked the steel steps out of frustration ? pulled himself together and began to take charge with paul ? ? at ? ? ? ? to the hard floor outside the ring from there ? began to ? ? throwing him with ease over the top rope ? landed painfully on his back then had to suffer from having his spine ? against the steel ring steps the fight returned to the ring with ? ? ? around the ? ? broke away and soon after ? ? with a kick to the temple ? followed with the rolling thunder but ? managed to kick out after a two count the fight looked like it might be over soon as ? went for a five star frog ? ? though ? van ? onto his shoulder and went for the f 5 but ? ? ? into a ? and followed with the frog ? he went for the pin but ? pulled the ? from the ring the ? immediately called for a ? and soon ? blows with ? after ? ? onto ? from the top rope and then threatened to hit the van terminator ? grabbed ? leg and ? picked up the ? and this time connected with the f 5 onto a steel chair winner ? br br match 6 booker t vs the big show booker t faced the big show one on one next show ? booker ? kicks and punches and slapped booker into the corner after being thrown from the ring booker picked up a chair at ? but big show ? it back into ? face booker tried to get back into the game by ? show with a camera cable at ? booker ? a tv ? from the spanish ? position into show's skull then delivered a ? kick that put both men through the table booker ? back into the ring and big show ? in moments later show grabbed ? throat but was met by a low blow and a kick to the face booker ? the top rope and nailed a ? leg drop to get the pin winner booker t br br ? triple h entered the ring to a ? ? as fans hoped to learn where the game would end up competing before he could speak eric ? stopped the game to apologize for getting involved in his personal business if triple h signed with raw ? promised his personal life would never come into play again ? said he's spent the past two years ? in hollywood he said everyone was looking for the next ? wwe superstar and they were all talking about triple h ? guaranteed that if triple h signed with raw he'd be getting top opportunities coming his way stephanie ? stepped out to issue her own pitch she said that because of her personal history with triple h the two of them know each other very well she said the two of them were once ? and they can be again ? cut her off and ? her to stop stephanie ? that triple h once told her how ? said triple h had no talent and no charisma ? said he was young at the time and didn't know what he had but he still has a lot more experience that stephanie the two continued to ? back and forth until triple h stepped up with his ? the game said it would be easy to say screw you to either one of them triple h went to shake ? hand but pulled it away he said he would rather go with the devil he knows rather than the one he doesn't know before he could go any further though shawn michaels came out to shake things up ? said the last thing he wanted to do was cause any trouble he didn't want to get involved but he remembered ? to bring triple h to the ? ? said there's nobody in the world that triple h is better friends with ? told his friend to imagine the two back together again making ? life a living hell triple h said that was a ? offer he then turned and ? ? making official his switch to raw triple h and ? left and ? ? over his victory ? said the difference between the two of them is that he's got ? and she doesn't stephanie whacked ? on the side of the head and left br br match 7 tag team championship match christian and lance storm vs hollywood hogan and edge the match started with loud usa ? and with hogan ? christian through the ? and out of the ring the ? took over from there but edge scored a kick to ? head and planted a ? on storm to get the tag to hogan hogan began to hulk up and soon caught christian with a big boot and a leg drop storm broke up the count and christian tossed hogan from the ring where storm ? the icon edge ? in soon after and dropped both opponents he ? both of them into the corner ? but missed a ? on ? and hit the ? hard instead edge nailed a ? but the ? was down and could not count test ? down and took down hogan then ? edge with a boot storm tried to get the pin but edge kicked out after two ? ? in to ? off test allowing edge to recover and ? storm christian distracted the ? though and ? ? in and ? edge with the tag team championship storm rolled over and got the ? to win the title winners and new tag team ? christian and lance storm br br match 8 wwe ? championship triple threat match the rock vs kurt angle and the undertaker three of ? most successful ? ? up against each other in a triple threat match with the ? championship hanging in the balance taker and the rock got face to face with kurt angle begging for some attention off to the side he got attention in the form of a beat down form the two other men soon after taker ? out of the ring and the rock ? with angle angle gave a series of ? that took down rock but the great one ? with a ? that managed a two count the fight continued outside the ring with taker coming to life and ? angle and repeatedly ? the rock taker and rock got into it back into the ring and taker dropped the rock with a sidewalk slam to get a two count rock ? grabbed taker by the throat and ? him angle broke up the pin attempt that likely would have given the rock the title the rock ? by ? on the ? lock to kurt angle angle ? the move and rock ? the people's champion soon after the rock ? of angle and hit the people's ? on the undertaker angle tried to take advantage by ? the great one outside the ring and covering taker who kicked out after a two count outside the ring rock took a big ? from a nearby water bottle and ? the ? into ? face to blind the champion taker didn't stay disabled for long and managed to ? rock and turn his attention to angle taker landed a ? leg drop onto angle laying on the ring ? the rock picked himself up just in time to break up a pin attempt on kurt angle taker nailed rock with a ? and set him up for a ? angle tried ? up with a steel chair but taker caught on to that ? and ? it out of his hands the ? got caught in the ensuing fire and didn't see angle knock taker silly with a steel chair angle went to cover taker as the rock lay prone but the dead man somehow got his shoulder up angle tried to pin rock but he too kicked out the rock got up and landed angle in the ? angle looked like he was about to tap but taker kicked the rock out of the ? hold taker picked rock up and crashed him with the last ride while the dead man covered him for the win angle ? in and picked taker up in the ? lock taker went delirious with pain but managed to counter he picked angle up for the last ride but angle put on a triangle choke it looked like taker was about to pass out but the rock broke ? hold only to find himself caught in the ? lock rock got out of the hold and watched taker ? angle rocky hit the rock bottom but taker refused to go down and kicked out angle ? taker up into the angle slam but was rock ? by the great one and ? winner and new wwe champion the rock br br finally there is a decent ? lately the ? weren't very good but this one was a winner i give this ? a a br br\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()    #mi prendo il dizionario\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])    #lo ribalto\n",
    "\n",
    "decoded_review = [reverse_word_index.get(i-3, '?') for i in longest_review]     #prendo l'indice - 3 perchè i primi 3 caratteri sono riservati\n",
    "decoded_review = ' '.join(decoded_review)    #lo trasformo in una frase\n",
    "decoded_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? i wouldn't rent this one even on dollar rental night\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortest_review = min(X_train, key=len)     #la recensione più corta contiene 11 parole\n",
    "decoded_review = [reverse_word_index.get(i-3, '?') for i in shortest_review]     #prendo l'indice - 3 perchè i primi 3 caratteri sono riservati\n",
    "decoded_review = ' '.join(decoded_review) \n",
    "decoded_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "portiamo tutte le recensioni alla stessa lunghezza: le tronco ed eventualmente aggiungo padding a quelle più corte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 50)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_lenght = 50\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=max_lenght, padding='post', truncating='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_lenght, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo la rete neurale ricorrente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.layers import Embedding, SimpleRNN      #per il word embedding lo aggiungiamo come se fosse uno strato della rete\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, 50))     #necessita del numero di parole e del numero di embedding da creare\n",
    "model.add(SimpleRNN(32))                #con 32 nodi, utilizza di default la tanh come funz di attivaz\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])  #rmsprop adatto per le cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.5215 - loss: 0.6928 - val_accuracy: 0.5952 - val_loss: 0.6659\n",
      "Epoch 2/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6927 - loss: 0.5983 - val_accuracy: 0.5914 - val_loss: 0.8599\n",
      "Epoch 3/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7449 - loss: 0.5416 - val_accuracy: 0.6342 - val_loss: 0.6486\n",
      "Epoch 4/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7967 - loss: 0.4570 - val_accuracy: 0.7242 - val_loss: 0.5548\n",
      "Epoch 5/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8198 - loss: 0.4157 - val_accuracy: 0.7478 - val_loss: 0.5264\n",
      "Epoch 6/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8645 - loss: 0.3390 - val_accuracy: 0.6694 - val_loss: 0.6541\n",
      "Epoch 7/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8858 - loss: 0.2924 - val_accuracy: 0.6774 - val_loss: 0.6349\n",
      "Epoch 8/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9359 - loss: 0.2058 - val_accuracy: 0.6656 - val_loss: 0.6710\n",
      "Epoch 9/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9602 - loss: 0.1483 - val_accuracy: 0.7416 - val_loss: 0.7028\n",
      "Epoch 10/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9551 - loss: 0.1445 - val_accuracy: 0.7450 - val_loss: 0.6698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2935b09e0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=512, validation_split=0.2, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "averfitting sul set di validazione, proviamo sul test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7364 - loss: 0.6853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6917542815208435, 0.7340800166130066]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)              #risultati scarsi perchè abbiamo utilizzato 50 parole (rimosso tanta informazione)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
